{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "import os\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws)\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
        "run = exp.start_logging()\n",
        "\n",
        "print('\\nFiles and directories:')\n",
        "fd = os.getcwd\n",
        "os.listdir(os.curdir)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace.create(name='quick-starts-ws-227257', subscription_id='cdbe0b43-92a0-4715-838a-f2648cc7ad21', resource_group='aml-quickstarts-227257')\nWorkspace name: quick-starts-ws-227257\nAzure region: southcentralus\nSubscription id: cdbe0b43-92a0-4715-838a-f2648cc7ad21\nResource group: aml-quickstarts-227257\n\nFiles and directories:\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "['.amlignore',\n '.amlignore.amltmp',\n '.ipynb_aml_checkpoints',\n 'conda_dependencies.yml',\n 'config.json',\n 'outputs',\n 'train.py',\n 'training',\n 'udacity-project.ipynb',\n 'udacity-project.ipynb.amltmp']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1678117281436
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "\n",
        "##cluster_name = \"GIVE_A_CLUSTER_NAME\"\n",
        "cluster_name = \"compute-cpu-cluster\"\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute cluster...')\n",
        "    # Specify the configuration for the new cluster\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2',\n",
        "                                idle_seconds_before_scaledown=2400, \n",
        "                                                        min_nodes=0,    # when inactive\n",
        "                                                        max_nodes=4)    # when busy\n",
        "    # Create the cluster with the specified name and configuration\n",
        "    compute_target = ComputeTarget.create(workspace=ws,\n",
        "                                       name=cluster_name, \n",
        "                                       provisioning_configuration=compute_config)\n",
        "\n",
        "# Wait for the cluster to complete, show the output log\n",
        "compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# use get_status() to get a detailed status for the current cluster. \n",
        "print(compute_target.get_status().serialize())\n",
        "\n",
        "print('\\nCheck details about compute_targets:')\n",
        "compute_targets = ws.compute_targets\n",
        "for name, ct in compute_targets.items():\n",
        "    print(name, ct.type, ct.provisioning_state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n\nRunning\n{'errors': [], 'creationTime': '2023-03-06T14:44:29.326606+00:00', 'createdBy': {'userObjectId': '38f16771-2e2d-44fb-b343-5fc4fc4aa048', 'userTenantId': '660b3398-b80e-49d2-bc5b-ac1dc93b5254', 'userName': None}, 'modifiedTime': '2023-03-06T14:47:37.240623+00:00', 'state': 'Running', 'vmSize': 'STANDARD_DS3_V2'}\n\nCheck details about compute_targets:\ncompute-cpu-cluster ComputeInstance Succeeded\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1678117287621
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Specify parameter sampler\n",
        "##ps = ### YOUR CODE HERE ###\n",
        "ps = RandomParameterSampling(\n",
        "            {\n",
        "                '--C': choice(0.01, 0.1, 1.0, 10.0, 100.0),\n",
        "                '--max_iter': choice(20, 50, 100, 120, 150)\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "# Specify a Policy\n",
        "##policy = ### YOUR CODE HERE ###\n",
        "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "train_script = \"./training\"\n",
        "shutil.copy('train.py', train_script)\n",
        "\n",
        "# Setup environment for your training run\n",
        "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies.yml')\n",
        "\n",
        "# Create a ScriptRunConfig Object to specify the configuration details of your training job\n",
        "##src = ### YOUR CODE HERE ###\n",
        "src = ScriptRunConfig(source_directory=train_script, \n",
        "                      script='train.py', \n",
        "                      compute_target=compute_target, \n",
        "                      environment=sklearn_env)\n",
        "\n",
        "# Create a HyperDriveConfig using the src object, hyperparameter sampler, and policy.\n",
        "##hyperdrive_config = ### YOUR CODE HERE ###\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src, \n",
        "                                     hyperparameter_sampling=ps, \n",
        "                                     policy=policy, \n",
        "                                     primary_metric_name='Accuracy',\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                                     max_total_runs=4,       \n",
        "                                     max_concurrent_runs=4)  "
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1678117291609
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Start the HyperDrive run\n",
        "hyperdrive_run = exp.submit(config = hyperdrive_config, show_output = True)\n",
        "\n",
        "# Monitor HyperDrive runs You can monitor the progress of the runs with the following Jupyter widget\n",
        "RunDetails(hyperdrive_run).show()\n",
        "\n",
        "# Wait for the cluster to complete, show the output log\n",
        "hyperdrive_run.wait_for_completion(show_output=True)\n",
        "\n",
        "# evaluate the the run is indeed complete\n",
        "assert(hyperdrive_run.get_status() == \"Completed\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe1ae3d8c89c46309ac1125a3a5f042e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_72e3dbeb-c80c-45de-8d52-1dc55d767742?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-227257/workspaces/quick-starts-ws-227257&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"HD_72e3dbeb-c80c-45de-8d52-1dc55d767742\", \"run_properties\": {\"run_id\": \"HD_72e3dbeb-c80c-45de-8d52-1dc55d767742\", \"created_utc\": \"2023-03-06T15:41:33.434379Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\":\\\"Accuracy\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"7acc0857-120b-4f9d-b74d-c48fbb21d060\", \"user_agent\": \"python/3.8.10 (Linux-5.15.0-1031-azure-x86_64-with-glibc2.17) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.48.0\", \"space_size\": \"25\", \"score\": \"0.9166919575113809\", \"best_child_run_id\": \"HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2\", \"best_metric_status\": \"Succeeded\", \"best_data_container_id\": \"dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"4\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\":\\\"Bandit\\\",\\\"properties\\\":{\\\"evaluation_interval\\\":2,\\\"delay_evaluation\\\":0,\\\"slack_factor\\\":0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\":\\\"RANDOM\\\",\\\"parameter_space\\\":{\\\"--C\\\":[\\\"choice\\\",[[0.01,0.1,1.0,10.0,100.0]]],\\\"--max_iter\\\":[\\\"choice\\\",[[20,50,100,120,150]]]},\\\"properties\\\":null}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\":\\\"Accuracy\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"SubscriptionId\\\": \\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-227257\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-227257\\\", \\\"ExperimentName\\\": \\\"udacity-project\\\", \\\"Definition\\\": {\\\"Configuration\\\": null, \\\"Attribution\\\": null, \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"25f89d04-2e48-4b3e-a274-914fb075d698\\\", \\\"amlClientSessionId\\\": \\\"c8c9b864-1a87-4fe5-b0b9-62425272515c\\\", \\\"subscriptionId\\\": \\\"cdbe0b43-92a0-4715-838a-f2648cc7ad21\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 4, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}, \\\"Overrides\\\": {\\\"Script\\\": \\\"train.py\\\", \\\"Command\\\": \\\"\\\", \\\"UseAbsolutePath\\\": false, \\\"Arguments\\\": [], \\\"SourceDirectoryDataStore\\\": null, \\\"Framework\\\": 0, \\\"Communicator\\\": 0, \\\"Target\\\": \\\"compute-cpu-cluster\\\", \\\"DataReferences\\\": {}, \\\"Data\\\": {}, \\\"OutputData\\\": {}, \\\"Datacaches\\\": [], \\\"JobName\\\": null, \\\"MaxRunDurationSeconds\\\": 2592000, \\\"NodeCount\\\": 1, \\\"InstanceTypes\\\": [], \\\"Priority\\\": null, \\\"CredentialPassthrough\\\": false, \\\"Identity\\\": null, \\\"Environment\\\": {\\\"Name\\\": \\\"sklearn-env\\\", \\\"AutoRebuild\\\": true, \\\"Python\\\": {\\\"InterpreterPath\\\": \\\"python\\\", \\\"UserManagedDependencies\\\": false, \\\"CondaDependencies\\\": {\\\"dependencies\\\": [\\\"python=3.6.2\\\", \\\"scikit-learn\\\", \\\"numpy\\\", \\\"pandas\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}]}, \\\"BaseCondaEnvironment\\\": null}, \\\"EnvironmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"Docker\\\": {\\\"BaseImage\\\": \\\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1\\\", \\\"Platform\\\": {\\\"Os\\\": \\\"Linux\\\", \\\"Architecture\\\": \\\"amd64\\\"}, \\\"BaseDockerfile\\\": null, \\\"BaseImageRegistry\\\": {\\\"Address\\\": null, \\\"Username\\\": null, \\\"Password\\\": null}, \\\"Enabled\\\": false, \\\"Arguments\\\": []}, \\\"Spark\\\": {\\\"Repositories\\\": [], \\\"Packages\\\": [], \\\"PrecachePackages\\\": true}, \\\"InferencingStackVersion\\\": null}, \\\"History\\\": {\\\"OutputCollection\\\": true, \\\"DirectoriesToWatch\\\": [\\\"logs\\\"], \\\"EnableMLflowTracking\\\": true, \\\"snapshotProject\\\": true}, \\\"Spark\\\": {\\\"Configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": \\\"1\\\"}}, \\\"ParallelTask\\\": {\\\"MaxRetriesPerWorker\\\": 0, \\\"WorkerCountPerNode\\\": 1, \\\"TerminalExitCodes\\\": null, \\\"Configuration\\\": {}}, \\\"BatchAi\\\": {\\\"NodeCount\\\": 0}, \\\"AmlCompute\\\": {\\\"Name\\\": null, \\\"VmSize\\\": null, \\\"RetainCluster\\\": false, \\\"ClusterMaxNodeCount\\\": null}, \\\"AISuperComputer\\\": {\\\"InstanceType\\\": \\\"D2\\\", \\\"FrameworkImage\\\": null, \\\"ImageVersion\\\": null, \\\"Location\\\": null, \\\"AISuperComputerStorageData\\\": null, \\\"Interactive\\\": false, \\\"ScalePolicy\\\": null, \\\"VirtualClusterArmId\\\": null, \\\"TensorboardLogDirectory\\\": null, \\\"SSHPublicKey\\\": null, \\\"SSHPublicKeys\\\": null, \\\"EnableAzmlInt\\\": true, \\\"Priority\\\": \\\"Medium\\\", \\\"SLATier\\\": \\\"Standard\\\", \\\"UserAlias\\\": null}, \\\"KubernetesCompute\\\": {\\\"InstanceType\\\": null}, \\\"Tensorflow\\\": {\\\"WorkerCount\\\": 1, \\\"ParameterServerCount\\\": 1}, \\\"Mpi\\\": {\\\"ProcessCountPerNode\\\": 1}, \\\"PyTorch\\\": {\\\"CommunicationBackend\\\": \\\"nccl\\\", \\\"ProcessCount\\\": null}, \\\"Hdi\\\": {\\\"YarnDeployMode\\\": 2}, \\\"ContainerInstance\\\": {\\\"Region\\\": null, \\\"CpuCores\\\": 2.0, \\\"MemoryGb\\\": 3.5}, \\\"ExposedPorts\\\": null, \\\"Docker\\\": {\\\"UseDocker\\\": false, \\\"SharedVolumes\\\": true, \\\"ShmSize\\\": \\\"2g\\\", \\\"Arguments\\\": []}, \\\"Cmk8sCompute\\\": {\\\"Configuration\\\": {}}, \\\"CommandReturnCodeConfig\\\": {\\\"ReturnCode\\\": 0, \\\"SuccessfulReturnCodes\\\": []}, \\\"EnvironmentVariables\\\": {}, \\\"ApplicationEndpoints\\\": {}, \\\"Parameters\\\": []}, \\\"SnapshotId\\\": \\\"7acc0857-120b-4f9d-b74d-c48fbb21d060\\\", \\\"Snapshots\\\": [], \\\"SourceCodeDataReference\\\": null, \\\"ParentRunId\\\": null, \\\"DataContainerId\\\": null, \\\"RunType\\\": null, \\\"DisplayName\\\": null, \\\"EnvironmentAssetId\\\": null, \\\"Properties\\\": {}, \\\"Tags\\\": {}, \\\"AggregatedArtifactPath\\\": null}, \\\"ParentRunId\\\": \\\"HD_72e3dbeb-c80c-45de-8d52-1dc55d767742\\\"}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2023-03-06T15:41:34.794261\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"333bba934f899f6b8f98d9b2981a9f022edddaa3f8d9f0d7bb33e2dbc7d2b9b3\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2023-03-06T15:41:34.794261\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_0\": \"{\\\"--C\\\": 100.0, \\\"--max_iter\\\": 20}\", \"_aml_system_HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_1\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 50}\", \"_aml_system_HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 120}\", \"_aml_system_HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_3\": \"{\\\"--C\\\": 1.0, \\\"--max_iter\\\": 20}\", \"_aml_system_final_best_metric_update_retry_count\": \"2\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-03-06T15:48:22.862374Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=hsUEvTbi4UsadyFGO5engXfa2mleaKrxOuoDVcnnBgs%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A49%3A01Z&se=2023-03-06T23%3A59%3A01Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:06:49\", \"run_number\": \"1678117293\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--C\": [\"choice\", [[0.01, 0.1, 1.0, 10.0, 100.0]]], \"--max_iter\": [\"choice\", [[20, 50, 100, 120, 150]]]}}, \"child_runs\": [{\"run_id\": \"HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2\", \"run_number\": 1678117296, \"metric\": 0.91669196, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-03-06T15:41:41.175788Z\", \"end_time\": \"2023-03-06T15:42:08.226836Z\", \"created_time\": \"2023-03-06T15:41:36.375237Z\", \"created_time_dt\": \"2023-03-06T15:41:36.375237Z\", \"duration\": \"0:00:31\", \"hyperdrive_id\": \"72e3dbeb-c80c-45de-8d52-1dc55d767742\", \"arguments\": null, \"param_--C\": 0.01, \"param_--max_iter\": 120, \"best_metric\": 0.91669196}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Regularization Strength:\": [{\"categories\": [1678117296], \"mode\": \"markers\", \"name\": \"Regularization Strength:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.01]}, {\"categories\": [1678117296], \"mode\": \"lines\", \"name\": \"Regularization Strength:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.01]}], \"Max iterations:\": [{\"categories\": [1678117296], \"mode\": \"markers\", \"name\": \"Max iterations:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [120]}, {\"categories\": [1678117296], \"mode\": \"lines\", \"name\": \"Max iterations:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [120]}], \"Accuracy\": [{\"categories\": [1678117296], \"mode\": \"markers\", \"name\": \"Accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9166919575113809]}, {\"categories\": [1678117296], \"mode\": \"lines\", \"name\": \"Accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9166919575113809]}]}, \"metricName\": null, \"primaryMetricName\": \"Accuracy\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_72e3dbeb-c80c-45de-8d52-1dc55d767742\", \"categories\": [0], \"series\": [{\"data\": [{\"time_elapse\": [64, 408], \"metric_value\": [0.9166919575113809, 0.9166919575113809], \"metric_name\": [\"Accuracy\", \"Accuracy\"], \"run_id\": [\"HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2\", \"HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2\"], \"final\": [false, true]}]}]}], \"run_logs\": \"[2023-03-06T15:41:34.351899][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\n[2023-03-06T15:41:35.4048152Z][SCHEDULER][INFO]Scheduling job, id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_0' \\n[2023-03-06T15:41:35.5283791Z][SCHEDULER][INFO]Scheduling job, id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_1' \\n[2023-03-06T15:41:35.6427769Z][SCHEDULER][INFO]Scheduling job, id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2' \\n[2023-03-06T15:41:35.712397][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\n[2023-03-06T15:41:35.7890928Z][SCHEDULER][INFO]Scheduling job, id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_3' \\n[2023-03-06T15:41:36.4105464Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_0' \\n[2023-03-06T15:41:36.4642522Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2' \\n[2023-03-06T15:41:36.5732784Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_3' \\n[2023-03-06T15:41:36.5763457Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_1' \\n[2023-03-06T15:42:06.529423][GENERATOR][INFO]Max number of jobs '4' reached for experiment.\\n[2023-03-06T15:42:06.697591][GENERATOR][INFO]All jobs generated.\\n[2023-03-06T15:48:23.126086][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.48.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: HD_72e3dbeb-c80c-45de-8d52-1dc55d767742\nWeb View: https://ml.azure.com/runs/HD_72e3dbeb-c80c-45de-8d52-1dc55d767742?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-227257/workspaces/quick-starts-ws-227257&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2023-03-06T15:41:34.351899][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n[2023-03-06T15:41:35.4048152Z][SCHEDULER][INFO]Scheduling job, id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_0' \n[2023-03-06T15:41:35.5283791Z][SCHEDULER][INFO]Scheduling job, id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_1' \n[2023-03-06T15:41:35.6427769Z][SCHEDULER][INFO]Scheduling job, id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2' \n[2023-03-06T15:41:35.712397][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n[2023-03-06T15:41:35.7890928Z][SCHEDULER][INFO]Scheduling job, id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_3' \n[2023-03-06T15:41:36.4105464Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_0' \n[2023-03-06T15:41:36.4642522Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2' \n[2023-03-06T15:41:36.5732784Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_3' \n[2023-03-06T15:41:36.5763457Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_1' \n[2023-03-06T15:42:06.529423][GENERATOR][INFO]Max number of jobs '4' reached for experiment.\n[2023-03-06T15:42:06.697591][GENERATOR][INFO]All jobs generated.\n[2023-03-06T15:48:23.126086][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\n\nExecution Summary\n=================\nRunId: HD_72e3dbeb-c80c-45de-8d52-1dc55d767742\nWeb View: https://ml.azure.com/runs/HD_72e3dbeb-c80c-45de-8d52-1dc55d767742?wsid=/subscriptions/cdbe0b43-92a0-4715-838a-f2648cc7ad21/resourcegroups/aml-quickstarts-227257/workspaces/quick-starts-ws-227257&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1678117705813
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "# get_children_sorted_by_primary_metric: Returns a list of children sorted by their best primary metric.\n",
        "# Each child in the result has run id, hyperparameters, best primary metric value and status.\n",
        "print(hyperdrive_run.get_children_sorted_by_primary_metric(top=0, reverse=False, discard_no_metric=False)) # top=1\n",
        "\n",
        "# Returns the best Run, or None if no child has the primary metric.\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "best_run\n",
        "\n",
        "print('\\nBest run ID: ', best_run.id)\n",
        "\n",
        "# Returns the metrics from all the runs that were launched by this HyperDriveRun.\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "best_run_metrics\n",
        "\n",
        "# check metrics details\n",
        "print(\"\\nBest run metrics :\",best_run.get_metrics())\n",
        "print('\\nAccuracy:', best_run_metrics['Accuracy'])\n",
        "\n",
        "# Returns a dictionary with the details for the run\n",
        "print(\"\\nBest run details :\",best_run.get_details())\n",
        "print(best_run.get_details()['runDefinition']['arguments'])\n",
        "\n",
        "# Returns a list of the files that are stored in association with the run.\n",
        "print(\"\\nBest run file names :\",best_run.get_file_names()) # get name of files of best_run\n",
        "\n",
        "# save file\n",
        "os.makedirs('./outputs',exist_ok = True)\n",
        "##joblib.dump(value=best_run, filename = 'outputs/bestHDModel.txt')\n",
        "joblib.dump(value=best_run, filename='outputs/bankmarketing_model.pkl')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[{'run_id': 'HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 120}', 'best_primary_metric': 0.9166919575113809, 'status': 'Completed'}, {'run_id': 'HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_1', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 50}', 'best_primary_metric': 0.9147192716236723, 'status': 'Completed'}, {'run_id': 'HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_0', 'hyperparameters': '{\"--C\": 100.0, \"--max_iter\": 20}', 'best_primary_metric': 0.9098634294385433, 'status': 'Completed'}, {'run_id': 'HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_3', 'hyperparameters': '{\"--C\": 1.0, \"--max_iter\": 20}', 'best_primary_metric': 0.9098634294385433, 'status': 'Completed'}]\n\nBest run ID:  HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2\n\nBest run metrics : {'Regularization Strength:': 0.01, 'Max iterations:': 120, 'Accuracy': 0.9166919575113809}\n\nAccuracy: 0.9166919575113809\n\nBest run details : {'runId': 'HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2', 'target': 'compute-cpu-cluster', 'status': 'Completed', 'startTimeUtc': '2023-03-06T15:41:41.175788Z', 'endTimeUtc': '2023-03-06T15:42:08.226836Z', 'services': {}, 'properties': {'_azureml.ComputeTargetType': 'amlcdsi', 'ContentSnapshotId': '7acc0857-120b-4f9d-b74d-c48fbb21d060', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'train.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--C', '0.01', '--max_iter', '120'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'compute-cpu-cluster', 'dataReferences': {}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': 2592000, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'sklearn-env', 'version': 'Autosave_2023-03-06T14:58:42Z_5721eb3a', 'assetId': 'azureml://locations/southcentralus/workspaces/f9cc2785-a3f5-40e9-aa2a-22ec1540a9b2/environments/sklearn-env/versions/Autosave_2023-03-06T14:58:42Z_5721eb3a', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'dependencies': ['python=3.6.2', 'scikit-learn', 'numpy', 'pandas', {'pip': ['azureml-defaults']}]}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': None}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/dataprep/0/backgroundProcess.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=NSS5VBHD8Qhx4vfBKHUHx%2B5u2k54e2lnLjtUK%2Fr%2Fkos%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=DGI0Cb%2FCX5t2i74YOdetLbdHE8DcZDd%2FjbHv%2BFaYS4U%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'logs/azureml/dataprep/0/rslex.log.2023-03-06-15': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/logs/azureml/dataprep/0/rslex.log.2023-03-06-15?sv=2019-07-07&sr=b&sig=UbNyQ3g91gb66qWCc3XIDnBGN6TGebvN%2BwOLLwxZfMk%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'user_logs/std_log.txt': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=DtYMJW6aX%2BPaYud61zEi4AlFkOiUk7Pmkwo8QJ%2Bw8eY%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'system_logs/cs_capability/cs-capability.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=%2BRrd7HLZoLKtuZRYQD1rLSXqtYKW5CD9svgx1AvXayU%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'system_logs/hosttools_capability/hosttools-capability.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=5Pu8r6aZAbRyUWl2QaAK19WSe9MseFJjdvLa4ZMz6uw%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'system_logs/lifecycler/execution-wrapper.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=B%2FonFxKtBESFtXfi%2BGjwdhHBf6deTBgt7l2swYOnyEc%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'system_logs/lifecycler/lifecycler.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=GIOsrSnMP2wb4nS3CERjKCle66dWTGdOPxXDuX8FeHU%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'system_logs/lifecycler/vm-bootstrapper.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/system_logs/lifecycler/vm-bootstrapper.log?sv=2019-07-07&sr=b&sig=d2QRpPtzmSWFZ21sp78p2gbUaD1cO8oKL%2BJ1G%2BeyuVc%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'system_logs/metrics_capability/metrics-capability.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=Gvte0itSxw5xDC6CJvIVaz1b4HiRivDUv6tLO2XOi5U%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r', 'system_logs/snapshot_capability/snapshot-capability.log': 'https://mlstrg227257.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72e3dbeb-c80c-45de-8d52-1dc55d767742_2/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=6jD%2B7HpAU%2FdM%2BC%2FeM0LGcDF5LtnsS5Ac%2B%2BhV0Fm8AwQ%3D&skoid=22449678-77a0-47c3-b490-38d5d199c8d6&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-06T14%3A48%3A43Z&ske=2023-03-07T22%3A58%3A43Z&sks=b&skv=2019-07-07&st=2023-03-06T15%3A38%3A28Z&se=2023-03-06T23%3A48%3A28Z&sp=r'}, 'submittedBy': 'ODL_User 227257'}\n['--C', '0.01', '--max_iter', '120']\n\nBest run file names : ['logs/azureml/dataprep/0/backgroundProcess.log', 'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log', 'logs/azureml/dataprep/0/rslex.log.2023-03-06-15', 'system_logs/cs_capability/cs-capability.log', 'system_logs/hosttools_capability/hosttools-capability.log', 'system_logs/lifecycler/execution-wrapper.log', 'system_logs/lifecycler/lifecycler.log', 'system_logs/lifecycler/vm-bootstrapper.log', 'system_logs/metrics_capability/metrics-capability.log', 'system_logs/snapshot_capability/snapshot-capability.log', 'user_logs/std_log.txt']\n"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot pickle '_queue.SimpleQueue' object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./outputs\u001b[39m\u001b[38;5;124m'\u001b[39m,exist_ok \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m##joblib.dump(value=best_run, filename = 'outputs/bestHDModel.txt')\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs/bankmarketing_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/joblib/numpy_pickle.py:505\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 505\u001b[0m         \u001b[43mNumpyPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m     NumpyPickler(filename, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mstart_framing()\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(STOP)\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframer\u001b[38;5;241m.\u001b[39mend_framing()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/joblib/numpy_pickle.py:295\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    292\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_setter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;66;03m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;66;03m# (obj, state) onto the stack.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/joblib/numpy_pickle.py:295\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    292\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
            "    \u001b[0;31m[... skipping similar frames: NumpyPickler.save at line 295 (1 times)]\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_setter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;66;03m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;66;03m# (obj, state) onto the stack.\u001b[39;00m\n",
            "    \u001b[0;31m[... skipping similar frames: NumpyPickler.save at line 295 (1 times)]\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
            "    \u001b[0;31m[... skipping similar frames: NumpyPickler.save at line 295 (5 times), _Pickler._batch_setitems at line 997 (2 times), _Pickler.save at line 603 (2 times), _Pickler.save at line 560 (2 times), _Pickler.save_dict at line 971 (2 times), _Pickler.save_reduce at line 717 (2 times)]\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple returned by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo to six elements\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m reduce)\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_setter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m         write(BUILD)\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;66;03m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;66;03m# to update obj's with its previous state.\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;66;03m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;66;03m# (obj, state) onto the stack.\u001b[39;00m\n",
            "    \u001b[0;31m[... skipping similar frames: NumpyPickler.save at line 295 (1 times)]\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    558\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mget(t)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call unbound method with explicit self\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;66;03m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# copyreg.dispatch_table\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite(MARK \u001b[38;5;241m+\u001b[39m DICT)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemoize(obj)\n\u001b[0;32m--> 971\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_setitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tmp:\n\u001b[1;32m    996\u001b[0m         save(k)\n\u001b[0;32m--> 997\u001b[0m         \u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m     write(SETITEMS)\n\u001b[1;32m    999\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m n:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/joblib/numpy_pickle.py:295\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    292\u001b[0m     wrapper\u001b[38;5;241m.\u001b[39mwrite_array(obj, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/pickle.py:578\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    576\u001b[0m reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m     reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_queue.SimpleQueue' object"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1678117709649
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "dataset = TabularDatasetFactory.from_delimited_files(path=url)\n",
        "\n",
        "# create a dataframe with ds data\n",
        "ds_df = dataset.to_pandas_dataframe()\n",
        "ds_df.head()\n",
        "ds_df.info()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1678117709897
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "\n",
        "##### My Code ################\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from azureml.core.dataset import Dataset\n",
        "##############################\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "##x, y = clean_data(### YOUR DATA OBJECT HERE ###)\n",
        "x, y = clean_data(dataset)\n",
        "\n",
        "dataset.take(3).to_pandas_dataframe()\n",
        "\n",
        "# split data into Train and Test Sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# combine the training features and the label\n",
        "train_df = pd.concat([x_train, y_train.to_frame(name=\"label\")], axis=1)\n",
        "validation_df = pd.concat([x_test, y_test.to_frame(name=\"label\")], axis=1)\n",
        "\n",
        "train_df.head()\n",
        "train_df.info()\n",
        "\n",
        "if not os.path.isdir('automl_data'):\n",
        "    os.mkdir('automl_data')\n",
        "\n",
        "# Save the train and validation data to a csv to be uploaded to the datastore\n",
        "train_df.to_csv(\"automl_data/train_data.csv\", index=False)\n",
        "validation_df.to_csv(\"automl_data/validation_data.csv\", index=False)\n",
        "\n",
        "ds = ws.get_default_datastore()\n",
        "ds.upload(src_dir='./automl_data', target_path='bankmarketing', overwrite=True, show_progress=True)\n",
        "\n",
        "# Upload the training data as a tabular dataset for access during training on remote compute\n",
        "############train_data = Dataset.Tabular.from_delimited_files(path=ds.path('bankmarketing/train_data.csv'))\n",
        "# validation_data = Dataset.Tabular.from_delimited_files(path=ds.path('bankmarketing/train_data.csv'))\n",
        "\n",
        "label = \"label\"\n",
        "############train_data.take(3).to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1678117709919
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "'''\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=,\n",
        "    primary_metric=,\n",
        "    training_data=,\n",
        "    label_column_name=,\n",
        "    n_cross_validations=)\n",
        "'''\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=\"classification\",\n",
        "    primary_metric=\"accuracy\",\n",
        "    training_data=train_df,\n",
        "    label_column_name='y',\n",
        "    n_cross_validations=5)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1678117709957
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######## My Code ######\n",
        "from azureml.widgets import RunDetails\n",
        "#######################\n",
        "\n",
        "# Submit your automl run\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "automl_run = exp.submit(automl_config, show_output=True)\n",
        "\n",
        "RunDetails(automl_run).show()\n",
        "\n",
        "# Wait to complete, show the output log\n",
        "####automl_run.wait_for_completion()\n",
        "automl_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1678117709977
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "best_run, fitted_model = remote_run.get_output()\n",
        "\n",
        "# get name of files of best_run\n",
        "best_run.get_file_names()\n",
        "print(best_run)\n",
        "print(fitted_model)\n",
        "\n",
        "# get_metrics()\n",
        "# Returns the metrics\n",
        "print(\"Best run metrics :\",best_run.get_metrics())\n",
        "\n",
        "# get_details()\n",
        "# Returns a dictionary with the details for the run\n",
        "print(\"Best run details :\",best_run.get_details())\n",
        "best_run.get_metrics()\n",
        "\n",
        "fitted_model\n",
        "best_run\n",
        "\n",
        "# Cluster clean up\n",
        "compute_target.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1678117709996
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}