{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-222154\n",
      "Azure region: southcentralus\n",
      "Subscription id: 3e42d11f-d64d-4173-af9b-12ecaa1030b3\n",
      "Resource group: aml-quickstarts-222154\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "####ws = Workspace.get(name=\"quick-starts-ws-222154\")\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute cluster...\n",
      "InProgress.\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2023-01-10T12:10:57.046000+00:00', 'errors': None, 'creationTime': '2023-01-10T12:10:51.817568+00:00', 'modifiedTime': '2023-01-10T12:10:58.499617+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT1800S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "##cluster_name = \"GIVE_A_CLUSTER_NAME\"\n",
    "cluster_name = \"compute-cluster\"\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute cluster...')\n",
    "    # Specify the configuration for the new cluster\n",
    "    ##compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2', max_nodes=4)\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    compute_target = ComputeTarget.create(workspace=ws,\n",
    "                                       name=cluster_name, \n",
    "                                       provisioning_configuration=compute_config)\n",
    "\n",
    "# Wait for the cluster to complete, show the output log\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
    "from azureml.core import Environment, ScriptRunConfig\n",
    "import os\n",
    "\n",
    "######## My Code ######\n",
    "import shutil\n",
    "#######################\n",
    "\n",
    "# Specify parameter sampler\n",
    "##ps = ### YOUR CODE HERE ###\n",
    "ps = RandomParameterSampling(\n",
    "            {\n",
    "                '--C': choice(0.01, 0.1, 1.0, 10.0, 100.0),\n",
    "                '--max_iter': choice(20, 50, 100, 120, 150)\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "# Specify a Policy\n",
    "##policy = ### YOUR CODE HERE ###\n",
    "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "######## My Code ######\n",
    "train_script = \"./training\"\n",
    "shutil.copy('train.py', train_script)\n",
    "#######################\n",
    "\n",
    "# Setup environment for your training run\n",
    "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies.yml')\n",
    "\n",
    "# Create a ScriptRunConfig Object to specify the configuration details of your training job\n",
    "##src = ### YOUR CODE HERE ###\n",
    "src = ScriptRunConfig(source_directory=train_script, \n",
    "                      script='train.py', \n",
    "                      compute_target=compute_target, \n",
    "                      environment=sklearn_env)\n",
    "\n",
    "# Create a HyperDriveConfig using the src object, hyperparameter sampler, and policy.\n",
    "##hyperdrive_config = ### YOUR CODE HERE ###\n",
    "hyperdrive_config = HyperDriveConfig(run_config=src, \n",
    "                                     hyperparameter_sampling=ps, \n",
    "                                     policy=policy, \n",
    "                                     primary_metric_name='validation_acc',            # Accuracy\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                                     max_total_runs=4,                                # 20, 100\n",
    "                                     max_concurrent_runs=4)                           # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf2b0ef857c497492cc8cd98ee5ad0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_fedcaf80-926d-41f8-99df-4aed00423ab1?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-222154/workspaces/quick-starts-ws-222154&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"HD_fedcaf80-926d-41f8-99df-4aed00423ab1\", \"run_properties\": {\"run_id\": \"HD_fedcaf80-926d-41f8-99df-4aed00423ab1\", \"created_utc\": \"2023-01-10T12:22:51.987851Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\":\\\"validation_acc\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"8ff7b21b-0218-486e-afd8-3baef82b8c05\", \"user_agent\": \"python/3.9.15 (Windows-10-10.0.19044-SP0) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.48.0\", \"space_size\": \"25\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"4\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\":\\\"Bandit\\\",\\\"properties\\\":{\\\"evaluation_interval\\\":2,\\\"delay_evaluation\\\":0,\\\"slack_factor\\\":0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\":\\\"RANDOM\\\",\\\"parameter_space\\\":{\\\"--C\\\":[\\\"choice\\\",[[0.01,0.1,1.0,10.0,100.0]]],\\\"--max_iter\\\":[\\\"choice\\\",[[20,50,100,120,150]]]},\\\"properties\\\":null}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\":\\\"validation_acc\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\":\\\"https://southcentralus.experiments.azureml.net\\\",\\\"SubscriptionId\\\":\\\"3e42d11f-d64d-4173-af9b-12ecaa1030b3\\\",\\\"ResourceGroupName\\\":\\\"aml-quickstarts-222154\\\",\\\"WorkspaceName\\\":\\\"quick-starts-ws-222154\\\",\\\"ExperimentName\\\":\\\"udacity-project\\\",\\\"Definition\\\":{\\\"Configuration\\\":null,\\\"Attribution\\\":null,\\\"TelemetryValues\\\":{\\\"amlClientType\\\":\\\"azureml-sdk-train\\\",\\\"amlClientModule\\\":\\\"[Scrubbed]\\\",\\\"amlClientFunction\\\":\\\"[Scrubbed]\\\",\\\"tenantId\\\":\\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\",\\\"amlClientRequestId\\\":\\\"85d88f73-640c-4bd0-99b0-f69c75057ce3\\\",\\\"amlClientSessionId\\\":\\\"8224e423-5c96-444e-b8b1-86ad5570484f\\\",\\\"subscriptionId\\\":\\\"3e42d11f-d64d-4173-af9b-12ecaa1030b3\\\",\\\"estimator\\\":\\\"NoneType\\\",\\\"samplingMethod\\\":\\\"RANDOM\\\",\\\"terminationPolicy\\\":\\\"Bandit\\\",\\\"primaryMetricGoal\\\":\\\"maximize\\\",\\\"maxTotalRuns\\\":4,\\\"maxConcurrentRuns\\\":4,\\\"maxDurationMinutes\\\":10080,\\\"vmSize\\\":null},\\\"Overrides\\\":{\\\"Script\\\":\\\"train.py\\\",\\\"Command\\\":\\\"\\\",\\\"UseAbsolutePath\\\":false,\\\"Arguments\\\":[],\\\"SourceDirectoryDataStore\\\":null,\\\"Framework\\\":0,\\\"Communicator\\\":0,\\\"Target\\\":\\\"compute-cluster\\\",\\\"DataReferences\\\":{},\\\"Data\\\":{},\\\"OutputData\\\":{},\\\"Datacaches\\\":[],\\\"JobName\\\":null,\\\"MaxRunDurationSeconds\\\":2592000,\\\"NodeCount\\\":1,\\\"InstanceTypes\\\":[],\\\"Priority\\\":null,\\\"CredentialPassthrough\\\":false,\\\"Identity\\\":null,\\\"Environment\\\":{\\\"Name\\\":\\\"sklearn-env\\\",\\\"AutoRebuild\\\":true,\\\"Python\\\":{\\\"InterpreterPath\\\":\\\"python\\\",\\\"UserManagedDependencies\\\":false,\\\"CondaDependencies\\\":{\\\"dependencies\\\":[\\\"python=3.6.2\\\",\\\"scikit-learn\\\",\\\"numpy\\\",\\\"pandas\\\",{\\\"pip\\\":[\\\"azureml-defaults\\\"]}]},\\\"BaseCondaEnvironment\\\":null},\\\"EnvironmentVariables\\\":{\\\"EXAMPLE_ENV_VAR\\\":\\\"EXAMPLE_VALUE\\\"},\\\"Docker\\\":{\\\"BaseImage\\\":\\\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1\\\",\\\"Platform\\\":{\\\"Os\\\":\\\"Linux\\\",\\\"Architecture\\\":\\\"amd64\\\"},\\\"BaseDockerfile\\\":null,\\\"BaseImageRegistry\\\":{\\\"Address\\\":null,\\\"Username\\\":null,\\\"Password\\\":null},\\\"Enabled\\\":false,\\\"Arguments\\\":[]},\\\"Spark\\\":{\\\"Repositories\\\":[],\\\"Packages\\\":[],\\\"PrecachePackages\\\":true},\\\"InferencingStackVersion\\\":null},\\\"History\\\":{\\\"OutputCollection\\\":true,\\\"DirectoriesToWatch\\\":[\\\"logs\\\"],\\\"EnableMLflowTracking\\\":true,\\\"snapshotProject\\\":true},\\\"Spark\\\":{\\\"Configuration\\\":{\\\"spark.app.name\\\":\\\"Azure ML Experiment\\\",\\\"spark.yarn.maxAppAttempts\\\":\\\"1\\\"}},\\\"ParallelTask\\\":{\\\"MaxRetriesPerWorker\\\":0,\\\"WorkerCountPerNode\\\":1,\\\"TerminalExitCodes\\\":null,\\\"Configuration\\\":{}},\\\"BatchAi\\\":{\\\"NodeCount\\\":0},\\\"AmlCompute\\\":{\\\"Name\\\":null,\\\"VmSize\\\":null,\\\"RetainCluster\\\":false,\\\"ClusterMaxNodeCount\\\":null},\\\"AISuperComputer\\\":{\\\"InstanceType\\\":\\\"D2\\\",\\\"FrameworkImage\\\":null,\\\"ImageVersion\\\":null,\\\"Location\\\":null,\\\"AISuperComputerStorageData\\\":null,\\\"Interactive\\\":false,\\\"ScalePolicy\\\":null,\\\"VirtualClusterArmId\\\":null,\\\"TensorboardLogDirectory\\\":null,\\\"SSHPublicKey\\\":null,\\\"SSHPublicKeys\\\":null,\\\"EnableAzmlInt\\\":true,\\\"Priority\\\":\\\"Medium\\\",\\\"SLATier\\\":\\\"Standard\\\",\\\"UserAlias\\\":null},\\\"KubernetesCompute\\\":{\\\"InstanceType\\\":null},\\\"Tensorflow\\\":{\\\"WorkerCount\\\":1,\\\"ParameterServerCount\\\":1},\\\"Mpi\\\":{\\\"ProcessCountPerNode\\\":1},\\\"PyTorch\\\":{\\\"CommunicationBackend\\\":\\\"nccl\\\",\\\"ProcessCount\\\":null},\\\"Hdi\\\":{\\\"YarnDeployMode\\\":2},\\\"ContainerInstance\\\":{\\\"Region\\\":null,\\\"CpuCores\\\":2.0,\\\"MemoryGb\\\":3.5},\\\"ExposedPorts\\\":null,\\\"Docker\\\":{\\\"UseDocker\\\":false,\\\"SharedVolumes\\\":true,\\\"ShmSize\\\":\\\"2g\\\",\\\"Arguments\\\":[]},\\\"Cmk8sCompute\\\":{\\\"Configuration\\\":{}},\\\"CommandReturnCodeConfig\\\":{\\\"ReturnCode\\\":0,\\\"SuccessfulReturnCodes\\\":[]},\\\"EnvironmentVariables\\\":{},\\\"ApplicationEndpoints\\\":{},\\\"Parameters\\\":[]},\\\"SnapshotId\\\":\\\"8ff7b21b-0218-486e-afd8-3baef82b8c05\\\",\\\"Snapshots\\\":[],\\\"SourceCodeDataReference\\\":null,\\\"ParentRunId\\\":null,\\\"DataContainerId\\\":null,\\\"RunType\\\":null,\\\"DisplayName\\\":null,\\\"EnvironmentAssetId\\\":null,\\\"Properties\\\":{},\\\"Tags\\\":{},\\\"AggregatedArtifactPath\\\":null},\\\"ParentRunId\\\":\\\"HD_fedcaf80-926d-41f8-99df-4aed00423ab1\\\"}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2023-01-10T12:22:52.717206\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"479dc986fcdb0b2759ac12a3423e1f740c46c77a534d9e2a91b10f19e33aafe1\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2023-01-10T12:22:52.717206\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_fedcaf80-926d-41f8-99df-4aed00423ab1_0\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 100}\", \"_aml_system_HD_fedcaf80-926d-41f8-99df-4aed00423ab1_1\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 120}\", \"_aml_system_HD_fedcaf80-926d-41f8-99df-4aed00423ab1_2\": \"{\\\"--C\\\": 10.0, \\\"--max_iter\\\": 20}\", \"_aml_system_HD_fedcaf80-926d-41f8-99df-4aed00423ab1_3\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 150}\", \"_aml_system_final_best_metric_update_retry_count\": \"1\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-01-10T12:40:26.638162Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg222154.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_fedcaf80-926d-41f8-99df-4aed00423ab1/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=m7VC%2FcHZZJZRy9Ly8pioc%2FVg3074cdKjsB1vxUq0CVY%3D&skoid=77475339-6383-46e5-ae9d-fcc7c8f3eec2&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-01-10T12%3A12%3A55Z&ske=2023-01-11T20%3A22%3A55Z&sks=b&skv=2019-07-07&st=2023-01-10T14%3A13%3A13Z&se=2023-01-10T22%3A23%3A13Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:17:34\", \"run_number\": \"1673353371\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--C\": [\"choice\", [[0.01, 0.1, 1.0, 10.0, 100.0]]], \"--max_iter\": [\"choice\", [[20, 50, 100, 120, 150]]]}}, \"child_runs\": [{\"run_id\": \"HD_fedcaf80-926d-41f8-99df-4aed00423ab1_2\", \"run_number\": 1673353374, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-01-10T12:36:00.503737Z\", \"end_time\": \"2023-01-10T12:37:28.111313Z\", \"created_time\": \"2023-01-10T12:22:54.502423Z\", \"created_time_dt\": \"2023-01-10T12:22:54.502423Z\", \"duration\": \"0:14:33\", \"hyperdrive_id\": \"fedcaf80-926d-41f8-99df-4aed00423ab1\", \"arguments\": null, \"param_--C\": 10.0, \"param_--max_iter\": 20}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2023-01-10T12:22:53.002003][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\n[2023-01-10T12:22:53.9690216Z][SCHEDULER][INFO]Scheduling job, id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_1' \\n[2023-01-10T12:22:54.0787224Z][SCHEDULER][INFO]Scheduling job, id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_2' \\n[2023-01-10T12:22:54.190745][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\n[2023-01-10T12:22:54.2803570Z][SCHEDULER][INFO]Scheduling job, id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_3' \\n[2023-01-10T12:22:54.6138195Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_2' \\n[2023-01-10T12:22:54.6581548Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_0' \\n[2023-01-10T12:22:53.8558081Z][SCHEDULER][INFO]Scheduling job, id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_0' \\n[2023-01-10T12:22:55.3079278Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_3' \\n[2023-01-10T12:22:55.3191290Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_1' \\n[2023-01-10T12:23:53.427543][GENERATOR][INFO]Max number of jobs '4' reached for experiment.\\n[2023-01-10T12:23:53.548342][GENERATOR][INFO]All jobs generated.\\n[2023-01-10T12:40:26.827626][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.48.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_fedcaf80-926d-41f8-99df-4aed00423ab1\n",
      "Web View: https://ml.azure.com/runs/HD_fedcaf80-926d-41f8-99df-4aed00423ab1?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-222154/workspaces/quick-starts-ws-222154&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "[2023-01-10T12:22:53.002003][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n",
      "[2023-01-10T12:22:53.9690216Z][SCHEDULER][INFO]Scheduling job, id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_1' \n",
      "[2023-01-10T12:22:54.0787224Z][SCHEDULER][INFO]Scheduling job, id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_2' \n",
      "[2023-01-10T12:22:54.190745][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n",
      "[2023-01-10T12:22:54.2803570Z][SCHEDULER][INFO]Scheduling job, id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_3' \n",
      "[2023-01-10T12:22:54.6138195Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_2' \n",
      "[2023-01-10T12:22:54.6581548Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_0' \n",
      "[2023-01-10T12:22:53.8558081Z][SCHEDULER][INFO]Scheduling job, id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_0' \n",
      "[2023-01-10T12:22:55.3079278Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_3' \n",
      "[2023-01-10T12:22:55.3191290Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_fedcaf80-926d-41f8-99df-4aed00423ab1_1' \n",
      "[2023-01-10T12:23:53.427543][GENERATOR][INFO]Max number of jobs '4' reached for experiment.\n",
      "[2023-01-10T12:23:53.548342][GENERATOR][INFO]All jobs generated.\n",
      "[2023-01-10T12:40:26.827626][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: HD_fedcaf80-926d-41f8-99df-4aed00423ab1\n",
      "Web View: https://ml.azure.com/runs/HD_fedcaf80-926d-41f8-99df-4aed00423ab1?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-222154/workspaces/quick-starts-ws-222154&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Start the HyperDrive run\n",
    "hyperdrive_run = exp.submit(config = hyperdrive_config, show_output = True)\n",
    "\n",
    "# Monitor HyperDrive runs You can monitor the progress of the runs with the following Jupyter widget\n",
    "RunDetails(hyperdrive_run).show()\n",
    "\n",
    "# Wait for the cluster to complete, show the output log\n",
    "hyperdrive_run.wait_for_completion(show_output=True)\n",
    "\n",
    "# evaluate the the run is indeed complete\n",
    "assert(hyperdrive_run.get_status() == \"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'run_id': 'HD_fedcaf80-926d-41f8-99df-4aed00423ab1_3', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 150}', 'best_primary_metric': None, 'status': 'Completed'}, {'run_id': 'HD_fedcaf80-926d-41f8-99df-4aed00423ab1_0', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 100}', 'best_primary_metric': None, 'status': 'Completed'}, {'run_id': 'HD_fedcaf80-926d-41f8-99df-4aed00423ab1_1', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 120}', 'best_primary_metric': None, 'status': 'Completed'}, {'run_id': 'HD_fedcaf80-926d-41f8-99df-4aed00423ab1_2', 'hyperparameters': '{\"--C\": 10.0, \"--max_iter\": 20}', 'best_primary_metric': None, 'status': 'Completed'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['outputs/bankmarketing_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# get_children_sorted_by_primary_metric: Returns a list of children sorted by their best primary metric.\n",
    "# Each child in the result has run id, hyperparameters, best primary metric value and status.\n",
    "print(hyperdrive_run.get_children_sorted_by_primary_metric(top=0, reverse=False, discard_no_metric=False)) # top=1\n",
    "\n",
    "# Returns the best Run, or None if no child has the primary metric.\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run\n",
    "\n",
    "########################################\n",
    "# get_metrics()\n",
    "# Returns the metrics from all the runs that were launched by this HyperDriveRun.\n",
    "#print(\"Best run metrics :\",best_run.get_metrics())\n",
    "#best_run_metrics = best_run.get_metrics()\n",
    "#print('Accuracy:', best_run_metrics['Accuracy'])\n",
    "\n",
    "# check metrics details\n",
    "#best_run_metrics\n",
    "\n",
    "#### --> object has no attribute 'get_metrics'\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# get_details()\n",
    "# Returns a dictionary with the details for the run\n",
    "#print(\"Best run details :\",best_run.get_details())\n",
    "#print(best_run.get_details()['runDefinition']['arguments'])\n",
    "\n",
    "#### --> object has no attribute 'get_details'\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# get_file_names()\n",
    "# Returns a list of the files that are stored in association with the run.\n",
    "#print(\"Best run file names :\",best_run.get_file_names()) # get name of files of best_run\n",
    "\n",
    "#### --> object has no attribute 'get_file_names'\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# download the best run and register the model\n",
    "#best_run.download_file(name=train_script+'/model.joblib', \n",
    "#                       output_file_path=train_script)\n",
    "\n",
    "#### --> object has no attribute 'download_file'\n",
    "########################################\n",
    "\n",
    "########################################\n",
    "# save the model, i.e., output file of best_run\n",
    "#model = best_run.register_model(model_name='hyperdrive_run', \n",
    "#                                model_path=train_script+'/model.joblib')\n",
    "\n",
    "#### --> object has no attribute 'register_model'\n",
    "########################################\n",
    "\n",
    "# save file\n",
    "os.makedirs('./outputs',exist_ok = True)\n",
    "joblib.dump(value=best_run, filename = 'outputs/bestHDModel.txt')\n",
    "joblib.dump(value=best_run, filename='outputs/bankmarketing_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32950 entries, 0 to 32949\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             32950 non-null  int64  \n",
      " 1   job             32950 non-null  object \n",
      " 2   marital         32950 non-null  object \n",
      " 3   education       32950 non-null  object \n",
      " 4   default         32950 non-null  object \n",
      " 5   housing         32950 non-null  object \n",
      " 6   loan            32950 non-null  object \n",
      " 7   contact         32950 non-null  object \n",
      " 8   month           32950 non-null  object \n",
      " 9   day_of_week     32950 non-null  object \n",
      " 10  duration        32950 non-null  int64  \n",
      " 11  campaign        32950 non-null  int64  \n",
      " 12  pdays           32950 non-null  int64  \n",
      " 13  previous        32950 non-null  int64  \n",
      " 14  poutcome        32950 non-null  object \n",
      " 15  emp.var.rate    32950 non-null  float64\n",
      " 16  cons.price.idx  32950 non-null  float64\n",
      " 17  cons.conf.idx   32950 non-null  float64\n",
      " 18  euribor3m       32950 non-null  float64\n",
      " 19  nr.employed     32950 non-null  float64\n",
      " 20  y               32950 non-null  object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "dataset = TabularDatasetFactory.from_delimited_files(path=url)\n",
    "\n",
    "# create a dataframe with ds data\n",
    "ds_df = dataset.to_pandas_dataframe()\n",
    "ds_df.head()\n",
    "ds_df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26360 entries, 26529 to 2732\n",
      "Data columns (total 40 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   age                            26360 non-null  int64  \n",
      " 1   marital                        26360 non-null  int64  \n",
      " 2   default                        26360 non-null  int64  \n",
      " 3   housing                        26360 non-null  int64  \n",
      " 4   loan                           26360 non-null  int64  \n",
      " 5   month                          26360 non-null  int64  \n",
      " 6   day_of_week                    26360 non-null  int64  \n",
      " 7   duration                       26360 non-null  int64  \n",
      " 8   campaign                       26360 non-null  int64  \n",
      " 9   pdays                          26360 non-null  int64  \n",
      " 10  previous                       26360 non-null  int64  \n",
      " 11  poutcome                       26360 non-null  int64  \n",
      " 12  emp.var.rate                   26360 non-null  float64\n",
      " 13  cons.price.idx                 26360 non-null  float64\n",
      " 14  cons.conf.idx                  26360 non-null  float64\n",
      " 15  euribor3m                      26360 non-null  float64\n",
      " 16  nr.employed                    26360 non-null  float64\n",
      " 17  job_admin.                     26360 non-null  uint8  \n",
      " 18  job_blue-collar                26360 non-null  uint8  \n",
      " 19  job_entrepreneur               26360 non-null  uint8  \n",
      " 20  job_housemaid                  26360 non-null  uint8  \n",
      " 21  job_management                 26360 non-null  uint8  \n",
      " 22  job_retired                    26360 non-null  uint8  \n",
      " 23  job_self-employed              26360 non-null  uint8  \n",
      " 24  job_services                   26360 non-null  uint8  \n",
      " 25  job_student                    26360 non-null  uint8  \n",
      " 26  job_technician                 26360 non-null  uint8  \n",
      " 27  job_unemployed                 26360 non-null  uint8  \n",
      " 28  job_unknown                    26360 non-null  uint8  \n",
      " 29  contact_cellular               26360 non-null  uint8  \n",
      " 30  contact_telephone              26360 non-null  uint8  \n",
      " 31  education_basic.4y             26360 non-null  uint8  \n",
      " 32  education_basic.6y             26360 non-null  uint8  \n",
      " 33  education_basic.9y             26360 non-null  uint8  \n",
      " 34  education_high.school          26360 non-null  uint8  \n",
      " 35  education_illiterate           26360 non-null  uint8  \n",
      " 36  education_professional.course  26360 non-null  uint8  \n",
      " 37  education_university.degree    26360 non-null  uint8  \n",
      " 38  education_unknown              26360 non-null  uint8  \n",
      " 39  label                          26360 non-null  int64  \n",
      "dtypes: float64(5), int64(13), uint8(22)\n",
      "memory usage: 4.4 MB\n",
      "Uploading an estimated of 2 files\n",
      "Uploading ./automl_data\\validation_data.csv\n",
      "Uploaded ./automl_data\\validation_data.csv, 1 files out of an estimated total of 2\n",
      "Uploading ./automl_data\\train_data.csv\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\data\\azure_storage_datastore.py\", line 353, in handler\n",
      "    result = future.result()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 439, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\data\\azure_storage_datastore.py\", line 934, in <lambda>\n",
      "    lambda target, source: lambda: [(self.blob_service.get_blob_client(\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\data\\azure_storage_datastore.py\", line 934, in <listcomp>\n",
      "    lambda target, source: lambda: [(self.blob_service.get_blob_client(\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 78, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_vendor\\azure_storage\\blob\\_blob_client.py\", line 731, in upload_blob\n",
      "    return upload_block_blob(**options)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_vendor\\azure_storage\\blob\\_upload_helpers.py\", line 107, in upload_block_blob\n",
      "    response = client.upload(\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\tracing\\decorator.py\", line 78, in wrapper_use_tracer\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_vendor\\azure_storage\\blob\\_generated\\operations\\_block_blob_operations.py\", line 805, in upload\n",
      "    pipeline_response = self._client._pipeline.run(  # type: ignore # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 211, in run\n",
      "    return first_node.send(pipeline_request)  # type: ignore\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\policies\\_redirect.py\", line 153, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_vendor\\azure_storage\\blob\\_shared\\policies.py\", line 544, in send\n",
      "    raise err\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_vendor\\azure_storage\\blob\\_shared\\policies.py\", line 518, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_vendor\\azure_storage\\blob\\_shared\\policies.py\", line 313, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 71, in send\n",
      "    response = self.next.send(request)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\_base.py\", line 103, in send\n",
      "    self._sender.send(request.http_request, **request.context.options),\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_vendor\\azure_storage\\blob\\_shared\\base_client.py\", line 330, in send\n",
      "    return self._transport.send(request, **kwargs)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py\", line 360, in send\n",
      "    raise error\n",
      "azure.core.exceptions.ServiceResponseError: ('Connection aborted.', timeout('The write operation timed out'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\logging\\__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\logging\\__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\logging\\__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\logging\\__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Viet\\AppData\\Local\\Temp\\ipykernel_9988\\2251170688.py\", line 33, in <module>\n",
      "    ds.upload(src_dir='./automl_data', target_path='bankmarketing', overwrite=True, show_progress=True)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\data\\_dataset_deprecation.py\", line 26, in wrapper\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\data\\azure_storage_datastore.py\", line 926, in upload\n",
      "    count = self._start_upload_task(\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\data\\azure_storage_datastore.py\", line 342, in _start_upload_task\n",
      "    tq.add_task(async_task)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_common\\async_utils\\task_queue.py\", line 55, in __exit__\n",
      "    self.flush(self.identity)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_common\\async_utils\\task_queue.py\", line 118, in flush\n",
      "    self._results.extend((task.wait(awaiter_name=self.identity) for task in completed_tasks))\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_common\\async_utils\\task_queue.py\", line 118, in <genexpr>\n",
      "    self._results.extend((task.wait(awaiter_name=self.identity) for task in completed_tasks))\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\_common\\async_utils\\async_task.py\", line 58, in wait\n",
      "    res = self._handler(self._future, self._logger)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\data\\azure_storage_datastore.py\", line 361, in handler\n",
      "    exception_handler(e, logger)\n",
      "  File \"C:\\Users\\Viet\\Anaconda3\\lib\\site-packages\\azureml\\data\\azure_storage_datastore.py\", line 325, in exception_handler\n",
      "    logger.error(\"Upload failed, please make sure target_path does not start with invalid characters.\", e)\n",
      "Message: 'Upload failed, please make sure target_path does not start with invalid characters.'\n",
      "Arguments: (ServiceResponseError(\"('Connection aborted.', timeout('The write operation timed out'))\"),)\n"
     ]
    }
   ],
   "source": [
    "from train import clean_data\n",
    "\n",
    "##### My Code ################\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from azureml.core.dataset import Dataset\n",
    "##############################\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "##x, y = clean_data(### YOUR DATA OBJECT HERE ###)\n",
    "x, y = clean_data(dataset)\n",
    "\n",
    "dataset.take(3).to_pandas_dataframe()\n",
    "\n",
    "# split data into Train and Test Sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# combine the training features and the label\n",
    "train_df = pd.concat([x_train, y_train.to_frame(name=\"label\")], axis=1)\n",
    "validation_df = pd.concat([x_test, y_test.to_frame(name=\"label\")], axis=1)\n",
    "\n",
    "train_df.head()\n",
    "train_df.info()\n",
    "\n",
    "if not os.path.isdir('automl_data'):\n",
    "    os.mkdir('automl_data')\n",
    "\n",
    "# Save the train and validation data to a csv to be uploaded to the datastore\n",
    "train_df.to_csv(\"automl_data/train_data.csv\", index=False)\n",
    "validation_df.to_csv(\"automl_data/validation_data.csv\", index=False)\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./automl_data', target_path='bankmarketing', overwrite=True, show_progress=True)\n",
    "\n",
    "# Upload the training data as a tabular dataset for access during training on remote compute\n",
    "############train_data = Dataset.Tabular.from_delimited_files(path=ds.path('bankmarketing/train_data.csv'))\n",
    "# validation_data = Dataset.Tabular.from_delimited_files(path=ds.path('bankmarketing/train_data.csv'))\n",
    "\n",
    "label = \"label\"\n",
    "############train_data.take(3).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml.train.automl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoMLConfig\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set parameters for AutoMLConfig\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# If you wish to run the experiment longer, you will need to run this notebook in your own\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Azure tenant, which will incur personal costs.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03mautoml_config = AutoMLConfig(\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    experiment_timeout_minutes=30,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    n_cross_validations=)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'azureml.train.automl'"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "'''\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task=,\n",
    "    primary_metric=,\n",
    "    training_data=,\n",
    "    label_column_name=,\n",
    "    n_cross_validations=)\n",
    "'''\n",
    "\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task=\"classification\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    training_data=train_df,\n",
    "    label_column_name='y',\n",
    "    n_cross_validations=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "######## My Code ######\n",
    "from azureml.widgets import RunDetails\n",
    "#######################\n",
    "\n",
    "# Submit your automl run\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "automl_run = exp.submit(automl_config, show_output=True)\n",
    "\n",
    "RunDetails(automl_run).show()\n",
    "\n",
    "# Wait to complete, show the output log\n",
    "####automl_run.wait_for_completion()\n",
    "automl_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "best_run, fitted_model = remote_run.get_output()\n",
    "\n",
    "# get name of files of best_run\n",
    "best_run.get_file_names()\n",
    "print(best_run)\n",
    "print(fitted_model)\n",
    "\n",
    "# get_metrics()\n",
    "# Returns the metrics\n",
    "print(\"Best run metrics :\",best_run.get_metrics())\n",
    "\n",
    "# get_details()\n",
    "# Returns a dictionary with the details for the run\n",
    "print(\"Best run details :\",best_run.get_details())\n",
    "best_run.get_metrics()\n",
    "\n",
    "fitted_model\n",
    "best_run\n",
    "\n",
    "# Cluster clean up\n",
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
