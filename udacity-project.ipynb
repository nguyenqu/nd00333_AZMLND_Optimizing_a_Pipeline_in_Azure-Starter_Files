{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: quick-starts-ws-227057\nAzure region: westeurope\nSubscription id: 81cefad3-d2c9-4f77-a466-99a7f541c7bb\nResource group: aml-quickstarts-227057\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1677764552030
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "\n",
        "##cluster_name = \"GIVE_A_CLUSTER_NAME\"\n",
        "cluster_name = \"compute-cluster-nguyenqu\"\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute cluster...')\n",
        "    # Specify the configuration for the new cluster\n",
        "    ##compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2', max_nodes=4)\n",
        "    # Create the cluster with the specified name and configuration\n",
        "    compute_target = ComputeTarget.create(workspace=ws,\n",
        "                                       name=cluster_name, \n",
        "                                       provisioning_configuration=compute_config)\n",
        "\n",
        "# Wait for the cluster to complete, show the output log\n",
        "compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# use get_status() to get a detailed status for the current cluster. \n",
        "print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n\nRunning\n{'errors': [], 'creationTime': '2023-03-02T13:07:17.972932+00:00', 'createdBy': {'userObjectId': 'daa1e2fb-b806-4b77-9fb1-ef79791abb34', 'userTenantId': '660b3398-b80e-49d2-bc5b-ac1dc93b5254', 'userName': None}, 'modifiedTime': '2023-03-02T13:30:00.312983+00:00', 'state': 'Running', 'vmSize': 'STANDARD_DS3_V2'}\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1677764559110
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice, uniform\n",
        "from azureml.core import Environment, ScriptRunConfig\n",
        "import os\n",
        "\n",
        "######## My Code ######\n",
        "import shutil\n",
        "#######################\n",
        "\n",
        "# Specify parameter sampler\n",
        "##ps = ### YOUR CODE HERE ###\n",
        "ps = RandomParameterSampling(\n",
        "            {\n",
        "                '--C': choice(0.01, 0.1, 1.0, 10.0, 100.0),\n",
        "                '--max_iter': choice(20, 50, 100, 120, 150)\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "# Specify a Policy\n",
        "##policy = ### YOUR CODE HERE ###\n",
        "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "######## My Code ######\n",
        "train_script = \"./training\"\n",
        "shutil.copy('train.py', train_script)\n",
        "#######################\n",
        "\n",
        "# Setup environment for your training run\n",
        "sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='conda_dependencies.yml')\n",
        "\n",
        "# Create a ScriptRunConfig Object to specify the configuration details of your training job\n",
        "##src = ### YOUR CODE HERE ###\n",
        "src = ScriptRunConfig(source_directory=train_script, \n",
        "                      script='train.py', \n",
        "                      compute_target=compute_target, \n",
        "                      environment=sklearn_env)\n",
        "\n",
        "# Create a HyperDriveConfig using the src object, hyperparameter sampler, and policy.\n",
        "##hyperdrive_config = ### YOUR CODE HERE ###\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src, \n",
        "                                     hyperparameter_sampling=ps, \n",
        "                                     policy=policy, \n",
        "                                     primary_metric_name='validation_acc',            # Accuracy\n",
        "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
        "                                     max_total_runs=4,                                # 20, 100\n",
        "                                     max_concurrent_runs=4)                           # 20"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1677764563457
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Start the HyperDrive run\n",
        "hyperdrive_run = exp.submit(config = hyperdrive_config, show_output = True)\n",
        "\n",
        "# Monitor HyperDrive runs You can monitor the progress of the runs with the following Jupyter widget\n",
        "RunDetails(hyperdrive_run).show()\n",
        "\n",
        "# Wait for the cluster to complete, show the output log\n",
        "hyperdrive_run.wait_for_completion(show_output=True)\n",
        "\n",
        "# evaluate the the run is indeed complete\n",
        "assert(hyperdrive_run.get_status() == \"Completed\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42317388c8b34532a08b9116fa326fef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_87480021-c0a5-4ace-93d1-2745fb26f23d?wsid=/subscriptions/81cefad3-d2c9-4f77-a466-99a7f541c7bb/resourcegroups/aml-quickstarts-227057/workspaces/quick-starts-ws-227057&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"HD_87480021-c0a5-4ace-93d1-2745fb26f23d\", \"run_properties\": {\"run_id\": \"HD_87480021-c0a5-4ace-93d1-2745fb26f23d\", \"created_utc\": \"2023-03-02T13:42:45.794138Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\":\\\"validation_acc\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"72072b34-56b3-444c-b1a4-bd3f569d6cc0\", \"user_agent\": \"python/3.8.10 (Linux-5.15.0-1031-azure-x86_64-with-glibc2.17) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.48.0\", \"space_size\": \"25\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"4\", \"_aml_system_max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\":\\\"Bandit\\\",\\\"properties\\\":{\\\"evaluation_interval\\\":2,\\\"delay_evaluation\\\":0,\\\"slack_factor\\\":0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\":\\\"RANDOM\\\",\\\"parameter_space\\\":{\\\"--C\\\":[\\\"choice\\\",[[0.01,0.1,1.0,10.0,100.0]]],\\\"--max_iter\\\":[\\\"choice\\\",[[20,50,100,120,150]]]},\\\"properties\\\":null}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\":\\\"validation_acc\\\",\\\"goal\\\":\\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\":\\\"https://westeurope.experiments.azureml.net\\\",\\\"SubscriptionId\\\":\\\"81cefad3-d2c9-4f77-a466-99a7f541c7bb\\\",\\\"ResourceGroupName\\\":\\\"aml-quickstarts-227057\\\",\\\"WorkspaceName\\\":\\\"quick-starts-ws-227057\\\",\\\"ExperimentName\\\":\\\"udacity-project\\\",\\\"Definition\\\":{\\\"Configuration\\\":null,\\\"Attribution\\\":null,\\\"TelemetryValues\\\":{\\\"amlClientType\\\":\\\"azureml-sdk-train\\\",\\\"amlClientModule\\\":\\\"[Scrubbed]\\\",\\\"amlClientFunction\\\":\\\"[Scrubbed]\\\",\\\"tenantId\\\":\\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\",\\\"amlClientRequestId\\\":\\\"eb178676-ea1d-4034-8c85-19ea8e8b4ce8\\\",\\\"amlClientSessionId\\\":\\\"dae1dd8f-c7f0-40b8-9814-cac793c4242d\\\",\\\"subscriptionId\\\":\\\"81cefad3-d2c9-4f77-a466-99a7f541c7bb\\\",\\\"estimator\\\":\\\"NoneType\\\",\\\"samplingMethod\\\":\\\"RANDOM\\\",\\\"terminationPolicy\\\":\\\"Bandit\\\",\\\"primaryMetricGoal\\\":\\\"maximize\\\",\\\"maxTotalRuns\\\":4,\\\"maxConcurrentRuns\\\":4,\\\"maxDurationMinutes\\\":10080,\\\"vmSize\\\":null},\\\"Overrides\\\":{\\\"Script\\\":\\\"train.py\\\",\\\"Command\\\":\\\"\\\",\\\"UseAbsolutePath\\\":false,\\\"Arguments\\\":[],\\\"SourceDirectoryDataStore\\\":null,\\\"Framework\\\":0,\\\"Communicator\\\":0,\\\"Target\\\":\\\"compute-cluster-nguyenqu\\\",\\\"DataReferences\\\":{},\\\"Data\\\":{},\\\"OutputData\\\":{},\\\"Datacaches\\\":[],\\\"JobName\\\":null,\\\"MaxRunDurationSeconds\\\":2592000,\\\"NodeCount\\\":1,\\\"InstanceTypes\\\":[],\\\"Priority\\\":null,\\\"CredentialPassthrough\\\":false,\\\"Identity\\\":null,\\\"Environment\\\":{\\\"Name\\\":\\\"sklearn-env\\\",\\\"AutoRebuild\\\":true,\\\"Python\\\":{\\\"InterpreterPath\\\":\\\"python\\\",\\\"UserManagedDependencies\\\":false,\\\"CondaDependencies\\\":{\\\"dependencies\\\":[\\\"python=3.6.2\\\",\\\"scikit-learn\\\",\\\"numpy\\\",\\\"pandas\\\",{\\\"pip\\\":[\\\"azureml-defaults\\\"]}]},\\\"BaseCondaEnvironment\\\":null},\\\"EnvironmentVariables\\\":{\\\"EXAMPLE_ENV_VAR\\\":\\\"EXAMPLE_VALUE\\\"},\\\"Docker\\\":{\\\"BaseImage\\\":\\\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1\\\",\\\"Platform\\\":{\\\"Os\\\":\\\"Linux\\\",\\\"Architecture\\\":\\\"amd64\\\"},\\\"BaseDockerfile\\\":null,\\\"BaseImageRegistry\\\":{\\\"Address\\\":null,\\\"Username\\\":null,\\\"Password\\\":null},\\\"Enabled\\\":false,\\\"Arguments\\\":[]},\\\"Spark\\\":{\\\"Repositories\\\":[],\\\"Packages\\\":[],\\\"PrecachePackages\\\":true},\\\"InferencingStackVersion\\\":null},\\\"History\\\":{\\\"OutputCollection\\\":true,\\\"DirectoriesToWatch\\\":[\\\"logs\\\"],\\\"EnableMLflowTracking\\\":true,\\\"snapshotProject\\\":true},\\\"Spark\\\":{\\\"Configuration\\\":{\\\"spark.app.name\\\":\\\"Azure ML Experiment\\\",\\\"spark.yarn.maxAppAttempts\\\":\\\"1\\\"}},\\\"ParallelTask\\\":{\\\"MaxRetriesPerWorker\\\":0,\\\"WorkerCountPerNode\\\":1,\\\"TerminalExitCodes\\\":null,\\\"Configuration\\\":{}},\\\"BatchAi\\\":{\\\"NodeCount\\\":0},\\\"AmlCompute\\\":{\\\"Name\\\":null,\\\"VmSize\\\":null,\\\"RetainCluster\\\":false,\\\"ClusterMaxNodeCount\\\":null},\\\"AISuperComputer\\\":{\\\"InstanceType\\\":\\\"D2\\\",\\\"FrameworkImage\\\":null,\\\"ImageVersion\\\":null,\\\"Location\\\":null,\\\"AISuperComputerStorageData\\\":null,\\\"Interactive\\\":false,\\\"ScalePolicy\\\":null,\\\"VirtualClusterArmId\\\":null,\\\"TensorboardLogDirectory\\\":null,\\\"SSHPublicKey\\\":null,\\\"SSHPublicKeys\\\":null,\\\"EnableAzmlInt\\\":true,\\\"Priority\\\":\\\"Medium\\\",\\\"SLATier\\\":\\\"Standard\\\",\\\"UserAlias\\\":null},\\\"KubernetesCompute\\\":{\\\"InstanceType\\\":null},\\\"Tensorflow\\\":{\\\"WorkerCount\\\":1,\\\"ParameterServerCount\\\":1},\\\"Mpi\\\":{\\\"ProcessCountPerNode\\\":1},\\\"PyTorch\\\":{\\\"CommunicationBackend\\\":\\\"nccl\\\",\\\"ProcessCount\\\":null},\\\"Hdi\\\":{\\\"YarnDeployMode\\\":2},\\\"ContainerInstance\\\":{\\\"Region\\\":null,\\\"CpuCores\\\":2.0,\\\"MemoryGb\\\":3.5},\\\"ExposedPorts\\\":null,\\\"Docker\\\":{\\\"UseDocker\\\":false,\\\"SharedVolumes\\\":true,\\\"ShmSize\\\":\\\"2g\\\",\\\"Arguments\\\":[]},\\\"Cmk8sCompute\\\":{\\\"Configuration\\\":{}},\\\"CommandReturnCodeConfig\\\":{\\\"ReturnCode\\\":0,\\\"SuccessfulReturnCodes\\\":[]},\\\"EnvironmentVariables\\\":{},\\\"ApplicationEndpoints\\\":{},\\\"Parameters\\\":[]},\\\"SnapshotId\\\":\\\"72072b34-56b3-444c-b1a4-bd3f569d6cc0\\\",\\\"Snapshots\\\":[],\\\"SourceCodeDataReference\\\":null,\\\"ParentRunId\\\":null,\\\"DataContainerId\\\":null,\\\"RunType\\\":null,\\\"DisplayName\\\":null,\\\"EnvironmentAssetId\\\":null,\\\"Properties\\\":{},\\\"Tags\\\":{},\\\"AggregatedArtifactPath\\\":null},\\\"ParentRunId\\\":\\\"HD_87480021-c0a5-4ace-93d1-2745fb26f23d\\\"}\", \"_aml_system_resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2023-03-02T13:42:47.116744\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"a4dc3cf676b632884a1d7a63313fdc6543dd334fd6f9123b65484c47288e8fbd\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2023-03-02T13:42:47.116744\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_87480021-c0a5-4ace-93d1-2745fb26f23d_0\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 150}\", \"_aml_system_HD_87480021-c0a5-4ace-93d1-2745fb26f23d_1\": \"{\\\"--C\\\": 100.0, \\\"--max_iter\\\": 150}\", \"_aml_system_HD_87480021-c0a5-4ace-93d1-2745fb26f23d_2\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 50}\", \"_aml_system_HD_87480021-c0a5-4ace-93d1-2745fb26f23d_3\": \"{\\\"--C\\\": 1.0, \\\"--max_iter\\\": 120}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2023-03-02T13:55:15.013102Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg227057.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_87480021-c0a5-4ace-93d1-2745fb26f23d/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=9UQCsHO8JH3Fx5pP3dUMh%2ByIg9MJv%2F6WpKKH8qeaOJU%3D&skoid=5a44ba68-6503-48eb-a572-303fd5aa2024&sktid=660b3398-b80e-49d2-bc5b-ac1dc93b5254&skt=2023-03-02T13%3A32%3A49Z&ske=2023-03-03T21%3A42%3A49Z&sks=b&skv=2019-07-07&st=2023-03-02T13%3A56%3A00Z&se=2023-03-02T22%3A06%3A00Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:12:29\", \"run_number\": \"1677764565\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"--C\": [\"choice\", [[0.01, 0.1, 1.0, 10.0, 100.0]]], \"--max_iter\": [\"choice\", [[20, 50, 100, 120, 150]]]}}, \"child_runs\": [{\"run_id\": \"HD_87480021-c0a5-4ace-93d1-2745fb26f23d_3\", \"run_number\": 1677764568, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-03-02T13:53:31.837878Z\", \"end_time\": \"2023-03-02T13:54:52.383629Z\", \"created_time\": \"2023-03-02T13:42:48.712027Z\", \"created_time_dt\": \"2023-03-02T13:42:48.712027Z\", \"duration\": \"0:12:03\", \"hyperdrive_id\": \"87480021-c0a5-4ace-93d1-2745fb26f23d\", \"arguments\": null, \"param_--C\": 1.0, \"param_--max_iter\": 120}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2023-03-02T13:42:46.890860][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\n[2023-03-02T13:42:47.9561093Z][SCHEDULER][INFO]Scheduling job, id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_1' \\n[2023-03-02T13:42:47.8335241Z][SCHEDULER][INFO]Scheduling job, id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_0' \\n[2023-03-02T13:42:48.0738533Z][SCHEDULER][INFO]Scheduling job, id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_2' \\n[2023-03-02T13:42:48.118031][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\n[2023-03-02T13:42:48.2286892Z][SCHEDULER][INFO]Scheduling job, id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_3' \\n[2023-03-02T13:42:48.8355579Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_0' \\n[2023-03-02T13:42:48.7909522Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_2' \\n[2023-03-02T13:42:48.8127028Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_3' \\n[2023-03-02T13:42:48.8535227Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_1' \\n[2023-03-02T13:43:18.358733][GENERATOR][INFO]Max number of jobs '4' reached for experiment.\\n[2023-03-02T13:43:18.508514][GENERATOR][INFO]All jobs generated.\\n[2023-03-02T13:55:15.359610][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.48.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: HD_87480021-c0a5-4ace-93d1-2745fb26f23d\nWeb View: https://ml.azure.com/runs/HD_87480021-c0a5-4ace-93d1-2745fb26f23d?wsid=/subscriptions/81cefad3-d2c9-4f77-a466-99a7f541c7bb/resourcegroups/aml-quickstarts-227057/workspaces/quick-starts-ws-227057&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\nStreaming azureml-logs/hyperdrive.txt\n=====================================\n\n[2023-03-02T13:42:46.890860][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\n[2023-03-02T13:42:47.9561093Z][SCHEDULER][INFO]Scheduling job, id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_1' \n[2023-03-02T13:42:47.8335241Z][SCHEDULER][INFO]Scheduling job, id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_0' \n[2023-03-02T13:42:48.0738533Z][SCHEDULER][INFO]Scheduling job, id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_2' \n[2023-03-02T13:42:48.118031][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\n[2023-03-02T13:42:48.2286892Z][SCHEDULER][INFO]Scheduling job, id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_3' \n[2023-03-02T13:42:48.8355579Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_0' \n[2023-03-02T13:42:48.7909522Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_2' \n[2023-03-02T13:42:48.8127028Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_3' \n[2023-03-02T13:42:48.8535227Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_87480021-c0a5-4ace-93d1-2745fb26f23d_1' \n[2023-03-02T13:43:18.358733][GENERATOR][INFO]Max number of jobs '4' reached for experiment.\n[2023-03-02T13:43:18.508514][GENERATOR][INFO]All jobs generated.\n[2023-03-02T13:55:15.359610][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\n\nExecution Summary\n=================\nRunId: HD_87480021-c0a5-4ace-93d1-2745fb26f23d\nWeb View: https://ml.azure.com/runs/HD_87480021-c0a5-4ace-93d1-2745fb26f23d?wsid=/subscriptions/81cefad3-d2c9-4f77-a466-99a7f541c7bb/resourcegroups/aml-quickstarts-227057/workspaces/quick-starts-ws-227057&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1677765360724
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "# get_children_sorted_by_primary_metric: Returns a list of children sorted by their best primary metric.\n",
        "# Each child in the result has run id, hyperparameters, best primary metric value and status.\n",
        "print(hyperdrive_run.get_children_sorted_by_primary_metric(top=0, reverse=False, discard_no_metric=False)) # top=1\n",
        "\n",
        "# Returns the best Run, or None if no child has the primary metric.\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "best_run\n",
        "\n",
        "########################################\n",
        "# get_metrics()\n",
        "# Returns the metrics from all the runs that were launched by this HyperDriveRun.\n",
        "#print(\"Best run metrics :\",best_run.get_metrics())\n",
        "#best_run_metrics = best_run.get_metrics()\n",
        "#print('Accuracy:', best_run_metrics['Accuracy'])\n",
        "\n",
        "# check metrics details\n",
        "#best_run_metrics\n",
        "\n",
        "#### --> object has no attribute 'get_metrics'\n",
        "########################################\n",
        "\n",
        "########################################\n",
        "# get_details()\n",
        "# Returns a dictionary with the details for the run\n",
        "#print(\"Best run details :\",best_run.get_details())\n",
        "#print(best_run.get_details()['runDefinition']['arguments'])\n",
        "\n",
        "#### --> object has no attribute 'get_details'\n",
        "########################################\n",
        "\n",
        "########################################\n",
        "# get_file_names()\n",
        "# Returns a list of the files that are stored in association with the run.\n",
        "#print(\"Best run file names :\",best_run.get_file_names()) # get name of files of best_run\n",
        "\n",
        "#### --> object has no attribute 'get_file_names'\n",
        "########################################\n",
        "\n",
        "########################################\n",
        "# download the best run and register the model\n",
        "#best_run.download_file(name=train_script+'/model.joblib', \n",
        "#                       output_file_path=train_script)\n",
        "\n",
        "#### --> object has no attribute 'download_file'\n",
        "########################################\n",
        "\n",
        "########################################\n",
        "# save the model, i.e., output file of best_run\n",
        "#model = best_run.register_model(model_name='hyperdrive_run', \n",
        "#                                model_path=train_script+'/model.joblib')\n",
        "\n",
        "#### --> object has no attribute 'register_model'\n",
        "########################################\n",
        "\n",
        "# save file\n",
        "os.makedirs('./outputs',exist_ok = True)\n",
        "joblib.dump(value=best_run, filename = 'outputs/bestHDModel.txt')\n",
        "joblib.dump(value=best_run, filename='outputs/bankmarketing_model.pkl')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[{'run_id': 'HD_87480021-c0a5-4ace-93d1-2745fb26f23d_1', 'hyperparameters': '{\"--C\": 100.0, \"--max_iter\": 150}', 'best_primary_metric': None, 'status': 'Completed'}, {'run_id': 'HD_87480021-c0a5-4ace-93d1-2745fb26f23d_2', 'hyperparameters': '{\"--C\": 0.01, \"--max_iter\": 50}', 'best_primary_metric': None, 'status': 'Completed'}, {'run_id': 'HD_87480021-c0a5-4ace-93d1-2745fb26f23d_0', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 150}', 'best_primary_metric': None, 'status': 'Completed'}, {'run_id': 'HD_87480021-c0a5-4ace-93d1-2745fb26f23d_3', 'hyperparameters': '{\"--C\": 1.0, \"--max_iter\": 120}', 'best_primary_metric': None, 'status': 'Completed'}]\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "['outputs/bankmarketing_model.pkl']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1677765362885
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "url = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "dataset = TabularDatasetFactory.from_delimited_files(path=url)\n",
        "\n",
        "# create a dataframe with ds data\n",
        "ds_df = dataset.to_pandas_dataframe()\n",
        "ds_df.head()\n",
        "ds_df.info()\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 32950 entries, 0 to 32949\nData columns (total 21 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   age             32950 non-null  int64  \n 1   job             32950 non-null  object \n 2   marital         32950 non-null  object \n 3   education       32950 non-null  object \n 4   default         32950 non-null  object \n 5   housing         32950 non-null  object \n 6   loan            32950 non-null  object \n 7   contact         32950 non-null  object \n 8   month           32950 non-null  object \n 9   day_of_week     32950 non-null  object \n 10  duration        32950 non-null  int64  \n 11  campaign        32950 non-null  int64  \n 12  pdays           32950 non-null  int64  \n 13  previous        32950 non-null  int64  \n 14  poutcome        32950 non-null  object \n 15  emp.var.rate    32950 non-null  float64\n 16  cons.price.idx  32950 non-null  float64\n 17  cons.conf.idx   32950 non-null  float64\n 18  euribor3m       32950 non-null  float64\n 19  nr.employed     32950 non-null  float64\n 20  y               32950 non-null  object \ndtypes: float64(5), int64(5), object(11)\nmemory usage: 5.3+ MB\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1677765379736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data\n",
        "\n",
        "##### My Code ################\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from azureml.core.dataset import Dataset\n",
        "##############################\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "##x, y = clean_data(### YOUR DATA OBJECT HERE ###)\n",
        "x, y = clean_data(dataset)\n",
        "\n",
        "dataset.take(3).to_pandas_dataframe()\n",
        "\n",
        "# split data into Train and Test Sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# combine the training features and the label\n",
        "train_df = pd.concat([x_train, y_train.to_frame(name=\"label\")], axis=1)\n",
        "validation_df = pd.concat([x_test, y_test.to_frame(name=\"label\")], axis=1)\n",
        "\n",
        "train_df.head()\n",
        "train_df.info()\n",
        "\n",
        "if not os.path.isdir('automl_data'):\n",
        "    os.mkdir('automl_data')\n",
        "\n",
        "# Save the train and validation data to a csv to be uploaded to the datastore\n",
        "train_df.to_csv(\"automl_data/train_data.csv\", index=False)\n",
        "validation_df.to_csv(\"automl_data/validation_data.csv\", index=False)\n",
        "\n",
        "ds = ws.get_default_datastore()\n",
        "ds.upload(src_dir='./automl_data', target_path='bankmarketing', overwrite=True, show_progress=True)\n",
        "\n",
        "# Upload the training data as a tabular dataset for access during training on remote compute\n",
        "############train_data = Dataset.Tabular.from_delimited_files(path=ds.path('bankmarketing/train_data.csv'))\n",
        "# validation_data = Dataset.Tabular.from_delimited_files(path=ds.path('bankmarketing/train_data.csv'))\n",
        "\n",
        "label = \"label\"\n",
        "############train_data.take(3).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 26360 entries, 26529 to 2732\nData columns (total 40 columns):\n #   Column                         Non-Null Count  Dtype  \n---  ------                         --------------  -----  \n 0   age                            26360 non-null  int64  \n 1   marital                        26360 non-null  int64  \n 2   default                        26360 non-null  int64  \n 3   housing                        26360 non-null  int64  \n 4   loan                           26360 non-null  int64  \n 5   month                          26360 non-null  int64  \n 6   day_of_week                    26360 non-null  int64  \n 7   duration                       26360 non-null  int64  \n 8   campaign                       26360 non-null  int64  \n 9   pdays                          26360 non-null  int64  \n 10  previous                       26360 non-null  int64  \n 11  poutcome                       26360 non-null  int64  \n 12  emp.var.rate                   26360 non-null  float64\n 13  cons.price.idx                 26360 non-null  float64\n 14  cons.conf.idx                  26360 non-null  float64\n 15  euribor3m                      26360 non-null  float64\n 16  nr.employed                    26360 non-null  float64\n 17  job_admin.                     26360 non-null  uint8  \n 18  job_blue-collar                26360 non-null  uint8  \n 19  job_entrepreneur               26360 non-null  uint8  \n 20  job_housemaid                  26360 non-null  uint8  \n 21  job_management                 26360 non-null  uint8  \n 22  job_retired                    26360 non-null  uint8  \n 23  job_self-employed              26360 non-null  uint8  \n 24  job_services                   26360 non-null  uint8  \n 25  job_student                    26360 non-null  uint8  \n 26  job_technician                 26360 non-null  uint8  \n 27  job_unemployed                 26360 non-null  uint8  \n 28  job_unknown                    26360 non-null  uint8  \n 29  contact_cellular               26360 non-null  uint8  \n 30  contact_telephone              26360 non-null  uint8  \n 31  education_basic.4y             26360 non-null  uint8  \n 32  education_basic.6y             26360 non-null  uint8  \n 33  education_basic.9y             26360 non-null  uint8  \n 34  education_high.school          26360 non-null  uint8  \n 35  education_illiterate           26360 non-null  uint8  \n 36  education_professional.course  26360 non-null  uint8  \n 37  education_university.degree    26360 non-null  uint8  \n 38  education_unknown              26360 non-null  uint8  \n 39  label                          26360 non-null  int64  \ndtypes: float64(5), int64(13), uint8(22)\nmemory usage: 4.4 MB\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1677765382746
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "'''\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=,\n",
        "    primary_metric=,\n",
        "    training_data=,\n",
        "    label_column_name=,\n",
        "    n_cross_validations=)\n",
        "'''\n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "    experiment_timeout_minutes=30,\n",
        "    task=\"classification\",\n",
        "    primary_metric=\"accuracy\",\n",
        "    training_data=train_df,\n",
        "    label_column_name='y',\n",
        "    n_cross_validations=5)\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1677765382970
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######## My Code ######\n",
        "from azureml.widgets import RunDetails\n",
        "#######################\n",
        "\n",
        "# Submit your automl run\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "automl_run = exp.submit(automl_config, show_output=True)\n",
        "\n",
        "RunDetails(automl_run).show()\n",
        "\n",
        "# Wait to complete, show the output log\n",
        "####automl_run.wait_for_completion()\n",
        "automl_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "No run_configuration provided, running on local with default configuration\nRunning in the active local environment.\n"
        },
        {
          "output_type": "error",
          "ename": "DataException",
          "evalue": "DataException:\n\tMessage: Expected column(s) y not found in X.\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Expected column(s) y not found in X.\",\n        \"target\": \"X\",\n        \"inner_error\": {\n            \"code\": \"BadArgument\",\n            \"inner_error\": {\n                \"code\": \"MissingColumnsInData\"\n            }\n        }\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDataException\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mazureml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunDetails\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#######################\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Submit your automl run\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m### YOUR CODE HERE ###\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m automl_run \u001b[38;5;241m=\u001b[39m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoml_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m RunDetails(automl_run)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Wait to complete, show the output log\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m####automl_run.wait_for_completion()\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/experiment.py:238\u001b[0m, in \u001b[0;36mExperiment.submit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m submit_func \u001b[38;5;241m=\u001b[39m get_experiment_submit(config)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmit config \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)):\n\u001b[0;32m--> 238\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43msubmit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     run\u001b[38;5;241m.\u001b[39mset_tags(tags)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/automlconfig.py:101\u001b[0m, in \u001b[0;36m_automl_static_submit\u001b[0;34m(automl_config_object, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m settings \u001b[38;5;241m=\u001b[39m _azureautomlsettings\u001b[38;5;241m.\u001b[39mAzureAutoMLSettings(experiment\u001b[38;5;241m=\u001b[39mexperiment, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_server\u001b[38;5;241m.\u001b[39mnew_log_context(parent_run_id\u001b[38;5;241m=\u001b[39mparent_run_id):\n\u001b[0;32m--> 101\u001b[0m     automl_run \u001b[38;5;241m=\u001b[39m \u001b[43m_start_execution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     automl_run\u001b[38;5;241m.\u001b[39madd_properties(global_tracking_info_registry\u001b[38;5;241m.\u001b[39mgather_all(settings\u001b[38;5;241m.\u001b[39mpath))\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m automl_run\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/automlconfig.py:223\u001b[0m, in \u001b[0;36m_start_execution\u001b[0;34m(experiment, settings_obj, fit_params, run_config, compute_target, parent_run_id, show_output)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m settings_obj\u001b[38;5;241m.\u001b[39m_ignore_package_version_incompatibilities:\n\u001b[1;32m    219\u001b[0m         package_utilities\u001b[38;5;241m.\u001b[39m_get_package_incompatibilities(\n\u001b[1;32m    220\u001b[0m             packages\u001b[38;5;241m=\u001b[39mpackage_utilities\u001b[38;5;241m.\u001b[39mAUTOML_PACKAGES,\n\u001b[1;32m    221\u001b[0m             ignored_dependencies\u001b[38;5;241m=\u001b[39mpackage_utilities\u001b[38;5;241m.\u001b[39m_PACKAGES_TO_IGNORE_VERSIONS\n\u001b[1;32m    222\u001b[0m         )\n\u001b[0;32m--> 223\u001b[0m     automl_run \u001b[38;5;241m=\u001b[39m \u001b[43m_default_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_run_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_managed:\n\u001b[1;32m    225\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubmitting local managed run.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/automlconfig.py:132\u001b[0m, in \u001b[0;36m_default_execution\u001b[0;34m(experiment, settings_obj, fit_params, legacy_local, show_output, parent_run_id)\u001b[0m\n\u001b[1;32m    130\u001b[0m experiment_state\u001b[38;5;241m.\u001b[39mconsole_writer\u001b[38;5;241m.\u001b[39mshow_output \u001b[38;5;241m=\u001b[39m show_output\n\u001b[1;32m    131\u001b[0m driver \u001b[38;5;241m=\u001b[39m ExperimentDriver(experiment_state)\n\u001b[0;32m--> 132\u001b[0m updated_params \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_parent_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m fit_params\u001b[38;5;241m.\u001b[39mupdate(updated_params)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mstart(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/_experiment_drivers/experiment_driver.py:205\u001b[0m, in \u001b[0;36mExperimentDriver.create_parent_run\u001b[0;34m(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m X, y, sample_weight, X_valid, y_valid, sample_weight_valid \u001b[38;5;241m=\u001b[39m dataset_utilities\u001b[38;5;241m.\u001b[39mconvert_inputs(\n\u001b[1;32m    186\u001b[0m     X, y, sample_weight, X_valid,\n\u001b[1;32m    187\u001b[0m     y_valid, sample_weight_valid\n\u001b[1;32m    188\u001b[0m )\n\u001b[1;32m    190\u001b[0m updated_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: X,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs\n\u001b[1;32m    203\u001b[0m }\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_parent_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_splits_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexisting_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_script_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_run_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mcurrent_run\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mparent_run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mcurrent_run\u001b[38;5;241m.\u001b[39mid\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/runtime/_experiment_drivers/local_experiment_driver.py:166\u001b[0m, in \u001b[0;36mLocalExperimentDriver.create_parent_run\u001b[0;34m(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m parent_run_dto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_parent_run_dto(serialized_datasets_json, parent_run_id)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Reads the user provided data, from all possible formats, into a raw experiment data\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_experiment_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_raw_experiment_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_splits_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_experiment_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mautoml_settings, parent_run_dto)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_parent_run_for_local(\n\u001b[1;32m    181\u001b[0m     parent_run_dto,\n\u001b[1;32m    182\u001b[0m     existing_run,\n\u001b[1;32m    183\u001b[0m     managed_run_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mautoml_settings\u001b[38;5;241m.\u001b[39m_local_managed_run_id,\n\u001b[1;32m    184\u001b[0m     _script_run\u001b[38;5;241m=\u001b[39m_script_run,\n\u001b[1;32m    185\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/train/automl/runtime/_experiment_drivers/local_experiment_driver.py:384\u001b[0m, in \u001b[0;36mLocalExperimentDriver.prepare_raw_experiment_data\u001b[0;34m(self, X, X_valid, cv_splits_indices, sample_weight, sample_weight_valid, training_data, validation_data, y, y_valid)\u001b[0m\n\u001b[1;32m    382\u001b[0m raw_experiment_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: Optional[RawExperimentData]\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     raw_experiment_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_preparation_utilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_raw_experiment_data_from_training_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoml_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     raw_experiment_data \u001b[38;5;241m=\u001b[39m data_preparation_utilities\u001b[38;5;241m.\u001b[39m_get_raw_experiment_data_legacy(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_state\u001b[38;5;241m.\u001b[39mautoml_settings,\n\u001b[1;32m    390\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m         cv_splits_indices,\n\u001b[1;32m    397\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/runtime/_data_preparation/data_preparation_utilities.py:162\u001b[0m, in \u001b[0;36m_get_raw_experiment_data_from_training_data\u001b[0;34m(training_data, automl_settings, validation_data)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m         Validation\u001b[38;5;241m.\u001b[39mvalidate_type(validation_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, expected_types\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_raw_experiment_data_from_pandas_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoml_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(training_data, TabularDataset):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validation_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/runtime/_data_preparation/data_preparation_utilities.py:64\u001b[0m, in \u001b[0;36m_get_raw_experiment_data_from_pandas_dataframe\u001b[0;34m(training_data, automl_settings, validation_data)\u001b[0m\n\u001b[1;32m     61\u001b[0m label_column_name \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, automl_settings\u001b[38;5;241m.\u001b[39mlabel_column_name)\n\u001b[1;32m     63\u001b[0m cv_splits_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m X, y, weights, cv_splits_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_utilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_data_from_combined_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoml_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_split_column_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoml_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_split_column_names\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m X_valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: Optional[pd.DataFrame]\u001b[39;00m\n\u001b[1;32m     71\u001b[0m y_valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: Optional[np.ndarray]\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/runtime/training_utilities.py:1079\u001b[0m, in \u001b[0;36m_extract_data_from_combined_dataframe\u001b[0;34m(training_data, label_column_name, sample_weight_column_name, cv_split_column_names)\u001b[0m\n\u001b[1;32m   1077\u001b[0m X \u001b[38;5;241m=\u001b[39m training_data[training_data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdifference(col_names_to_drop)]\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_column_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m training_data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1079\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataException\u001b[38;5;241m.\u001b[39m_with_error(\n\u001b[1;32m   1080\u001b[0m         AzureMLError\u001b[38;5;241m.\u001b[39mcreate(MissingColumnsInData, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, columns\u001b[38;5;241m=\u001b[39mlabel_column_name, data_object_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1081\u001b[0m     )\n\u001b[1;32m   1082\u001b[0m y \u001b[38;5;241m=\u001b[39m training_data[label_column_name]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, sample_weight, cv_splits_indices\n",
            "\u001b[0;31mDataException\u001b[0m: DataException:\n\tMessage: Expected column(s) y not found in X.\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Expected column(s) y not found in X.\",\n        \"target\": \"X\",\n        \"inner_error\": {\n            \"code\": \"BadArgument\",\n            \"inner_error\": {\n                \"code\": \"MissingColumnsInData\"\n            }\n        }\n    }\n}"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1677765403537
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "best_run, fitted_model = remote_run.get_output()\n",
        "\n",
        "# get name of files of best_run\n",
        "best_run.get_file_names()\n",
        "print(best_run)\n",
        "print(fitted_model)\n",
        "\n",
        "# get_metrics()\n",
        "# Returns the metrics\n",
        "print(\"Best run metrics :\",best_run.get_metrics())\n",
        "\n",
        "# get_details()\n",
        "# Returns a dictionary with the details for the run\n",
        "print(\"Best run details :\",best_run.get_details())\n",
        "best_run.get_metrics()\n",
        "\n",
        "fitted_model\n",
        "best_run\n",
        "\n",
        "# Cluster clean up\n",
        "compute_target.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1677765403652
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}